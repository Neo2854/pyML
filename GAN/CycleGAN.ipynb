{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import optim\n",
    "import tensorboard\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_data_path = \"./celeb_dataset/\"\n",
    "bitmoji_path = \"./Bitmoji-Faces/\"\n",
    "\n",
    "img_size = 64\n",
    "no_channels = 3\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(no_channels)], [0.5 for _ in range(no_channels)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "celeb_dataset = datasets.ImageFolder(root=\"./celeb_dataset/\", transform=transform)\n",
    "bitmoji_dataset = datasets.ImageFolder(root=bitmoji_path, transform=transform)\n",
    "\n",
    "celeb_dataloader = DataLoader(celeb_dataset, batch_size, shuffle=True)\n",
    "bitmoji_dataloader = DataLoader(bitmoji_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
    "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
    "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
    "            ]\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "        x = self.res_blocks(x)\n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last(x))\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if isinstance(m,nn.BatchNorm2d):\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m real_x \u001b[38;5;241m=\u001b[39m celeb_dataset[rand_x]\n\u001b[1;32m     48\u001b[0m real_y \u001b[38;5;241m=\u001b[39m bitmoji_dataset[rand_y]\n\u001b[0;32m---> 49\u001b[0m real_x \u001b[38;5;241m=\u001b[39m \u001b[43mreal_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     50\u001b[0m real_y \u001b[38;5;241m=\u001b[39m real_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Train discriminator x\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 5\n",
    "GRADIENT_PENALITY_LAMBDA = 10\n",
    "LAMBDA_CYCLE = 10\n",
    "LAMBDA_IDENTITY = 1\n",
    "\n",
    "gen_x = Generator(3).to(device)\n",
    "gen_y = Generator(3).to(device)\n",
    "disc_x = Discriminator(3, 64).to(device)\n",
    "disc_y = Discriminator(3, 64).to(device)\n",
    "\n",
    "writer_1 = SummaryWriter(f\"logs/real\")\n",
    "writer_2 = SummaryWriter(f\"logs/fake\")\n",
    "\n",
    "opt_gen = optim.Adam(\n",
    "    list(gen_x.parameters()) + list(gen_y.parameters()),\n",
    "    LEARNING_RATE,\n",
    "    (0.5, 0.999)\n",
    ")\n",
    "\n",
    "opt_disc_x = optim.Adam(disc_x.parameters(), LEARNING_RATE, (0.5, 0.999))\n",
    "opt_disc_y = optim.Adam(disc_y.parameters(), LEARNING_RATE, (0.5, 0.999))\n",
    "\n",
    "l1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# for tensorboard plotting\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen_x.train()\n",
    "gen_y.train()\n",
    "disc_x.train()\n",
    "disc_y.train()\n",
    "\n",
    "num_iters = 100000\n",
    "step = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for iter in range(num_iters):\n",
    "        rand_x = random.randint(0, num_iters)\n",
    "        rand_y = random.randint(0, num_iters)\n",
    "\n",
    "        real_x = celeb_dataset[rand_x]\n",
    "        real_y = bitmoji_dataset[rand_y]\n",
    "        real_x = real_x.to(device)\n",
    "        real_y = real_y.to(device)\n",
    "\n",
    "        # Train discriminator x\n",
    "        fake_x = gen_x(real_x)\n",
    "        d_x_real = disc_x(real_x).reshape(-1)\n",
    "        d_x_fake = disc_x(fake_x.detach()).reshape(-1)\n",
    "        gp = gradient_penalty(disc_x, real_x, fake_x, device)\n",
    "        loss_disc_x = -(torch.mean(d_x_real) - torch.mean(d_x_fake)) + GRADIENT_PENALITY_LAMBDA * gp\n",
    "        opt_disc_x.zero_grad()\n",
    "        loss_disc_x.backward(retain_graph=True)\n",
    "        opt_disc_x.step()\n",
    "\n",
    "        #Train discriminator y\n",
    "        fake_y = gen_x(real_y)\n",
    "        d_y_real = disc_y(real_y).reshape(-1)\n",
    "        d_y_fake = disc_y(fake_y.detach()).reshape(-1)\n",
    "        gp = gradient_penalty(disc_y, real_y, fake_y, device)\n",
    "        loss_disc_y = -(torch.mean(d_y_real) - torch.mean(d_y_fake)) + GRADIENT_PENALITY_LAMBDA * gp\n",
    "        opt_disc_y.zero_grad()\n",
    "        loss_disc_y.backward(retain_graph=True)\n",
    "        opt_disc_y.step()\n",
    "\n",
    "        # Adveserial Loss\n",
    "        gen_x_fake = disc_x(fake_x).reshape(-1)\n",
    "        loss_gen_x = -torch.mean(gen_x_fake)\n",
    "        gen_Y_fake = disc_y(fake_y).reshape(-1)\n",
    "        loss_gen_y = -torch.mean(gen_Y_fake)\n",
    "\n",
    "        # Cycle Loss\n",
    "        cycle_x = gen_x(fake_y)\n",
    "        cycle_y = gen_y(fake_x)\n",
    "        cycle_x_loss = l1(real_x, cycle_x)\n",
    "        cycle_y_loss = l1(real_y, cycle_y)\n",
    "\n",
    "        # Identity Loss\n",
    "        id_x = gen_x(real_x)\n",
    "        id_y = gen_y(real_y)\n",
    "        id_x_loss = l1(real_x, id_x)\n",
    "        id_y_loss = l1(real_y, id_y)\n",
    "\n",
    "        net_gen_loss = (\n",
    "            loss_gen_x +\n",
    "            loss_gen_y +\n",
    "            (cycle_x_loss * LAMBDA_CYCLE) +\n",
    "            (cycle_y_loss * LAMBDA_CYCLE) +\n",
    "            (id_x_loss * LAMBDA_IDENTITY) +\n",
    "            (id_y_loss * LAMBDA_IDENTITY)\n",
    "        )\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        net_gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                index = random.randint(0, num_iters)\n",
    "\n",
    "                x = celeb_dataset[index]\n",
    "                y = bitmoji_dataset[index]\n",
    "\n",
    "                fake_x = gen_x(y)\n",
    "                fake_y = gen_y(x)\n",
    "                cycle_x = gen_x(fake_y)\n",
    "                cycle_y = gen_y(fake_x)\n",
    "\n",
    "                img_grid_1 = torchvision.utils.make_grid([x, fake_y, cycle_x], nrow=3, normalize=True)\n",
    "                img_grid_2 = torchvision.utils.make_grid([y, fake_x, cycle_y], nrow=3, normalize=True)\n",
    "\n",
    "                writer_1.add_image(\"Domain 1\", img_grid_1, step)\n",
    "                writer_2.add_image(\"Domain 2\", img_grid_2, step)\n",
    "\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
       "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (res_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ADRL': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f09f5b5b51b597f1c6c549016ce33f987109769ac8e4eb3f83f958c2707f7a74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
